# Telegram AI Bot Project Context & Goal

## Goal for the LLM
You are an expert Python developer and AI bot architect with deep expertise in:
- Telegram Bot API and python-telegram-bot library
- AI/LLM integration (OpenAI/OpenRouter APIs)
- Database design with Supabase/PostgreSQL
- Modern Python development with UV package manager
- Bot conversation design and user experience

Your task is to analyze the complete context of this Telegram AI Bot project. The bot features:
- Two AI personalities (Product Manager & VC/Angel Investor)
- Conversation persistence with Supabase
- Real-time AI responses via OpenRouter/Perplexity
- Rich Telegram UI with inline keyboards
- User statistics and session management

Please review the project structure, dependencies, source code, database schema, and configuration,
then provide specific, actionable advice for improvement. Focus on:
- Code quality and Python best practices
- Bot conversation flow and UX
- Database optimization and design
- AI prompt engineering and response quality
- Security and error handling
- Performance and scalability
- Deployment and production readiness

---

## Directory Structure
.
â”œâ”€â”€ Procfile
â”œâ”€â”€ README.md
â”œâ”€â”€ generate-context.sh
â”œâ”€â”€ main.py
â”œâ”€â”€ migrations
â”‚Â Â  â”œâ”€â”€ 001_initial_schema.sql
â”‚Â Â  â”œâ”€â”€ 002_analytics_table.sql
â”‚Â Â  â””â”€â”€ 003_conversation_summaries.sql
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ render.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts
â”‚Â Â  â”œâ”€â”€ analytics_report.py
â”‚Â Â  â”œâ”€â”€ basic_analytics_report.py
â”‚Â Â  â”œâ”€â”€ run_migrations.py
â”‚Â Â  â”œâ”€â”€ test_datetime_fix.py
â”‚Â Â  â”œâ”€â”€ test_enhanced_bot.py
â”‚Â Â  â”œâ”€â”€ test_openrouter.py
â”‚Â Â  â”œâ”€â”€ test_supabase.py
â”‚Â Â  â””â”€â”€ test_telegram_bot.py
â”œâ”€â”€ src
â”‚Â Â  â””â”€â”€ bot
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â”œâ”€â”€ __main__.py
â”‚Â Â      â”œâ”€â”€ agents.py
â”‚Â Â      â”œâ”€â”€ config.py
â”‚Â Â      â”œâ”€â”€ database.py
â”‚Â Â      â”œâ”€â”€ handlers.py
â”‚Â Â      â”œâ”€â”€ main.py
â”‚Â Â      â”œâ”€â”€ middleware.py
â”‚Â Â      â””â”€â”€ utils.py
â”œâ”€â”€ telegram-bot-context-prompt-20250810-2224.txt
â””â”€â”€ tests
    â”œâ”€â”€ __init__.py
    â””â”€â”€ test_database.py

6 directories, 30 files

## FILE: README.md
# Starknet Founders Bot v2

AI-powered Telegram bot for Starknet founders with two expert advisor personalities.

## Features

- **Product Manager Mode**: Based on Lenny Rachitsky's frameworks
- **VC/Angel Investor Mode**: Current market insights and fundraising advice
- **Real-time Data**: Powered by Perplexity with internet access
- **Conversation Memory**: Persistent chat history with Supabase
- **Usage Analytics**: Track your conversations and statistics

## ðŸ› ï¸ Tech Stack

- Python 3.11+ with UV package manager
- Telegram Bot API (python-telegram-bot)
- OpenRouter API (Perplexity models)
- Supabase (PostgreSQL database)
- Async/await architecture

## Quick Start

1. Clone the repository
2. Copy `.env.example` to `.env` and fill in your credentials
3. Install dependencies: `uv sync`
4. Run migrations in Supabase
5. Start the bot: `uv run python -m bot.main`

## Usage

1. Start chat: [@starknet_advisor_bot](https://t.me/starknet_advisor_bot)
2. Choose your advisor (PM or VC)
3. Ask questions about your startup!

## ðŸ”‘ Environment Variables

See `.env.example` for required variables.

## ðŸ“„ License

MIT

---

Built with â¤ï¸ for the Starknet ecosystem
---

## FILE: pyproject.toml
[project]
name = "telegram-ai-bot"
version = "0.1.0"
description = "AI-powered Telegram bot with PM and VC personalities"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "python-telegram-bot>=20.7",
    "openai>=1.35.3",
    "supabase>=2.3.0",
    "python-dotenv>=1.0.0",
    "pydantic>=2.5.0",
    "aiohttp>=3.9.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/bot"]

[tool.uv]
dev-dependencies = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
    "mypy>=1.7.0",
    "ipython>=8.0.0",
]

[tool.ruff]
line-length = 88
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "UP", "ANN", "B", "A", "COM", "C4", "DTZ", "ISC", "ICN", "PIE", "PT", "RET", "SIM", "ARG"]
# ANN101 and ANN102 have been removed from ruff, so no need to ignore them

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
---

## FILE: .env.example
# Supabase
SUPABASE_URL=https://xxxxxxxxxxxx.supabase.co
SUPABASE_SERVICE_KEY=your-service-key-here

# OpenRouter
OPENROUTER_API_KEY=sk-or-v1-xxxxx

# Telegram
TELEGRAM_BOT_TOKEN=123456:ABC-DEF1234ghIkl-zyx57W2v1u123ew11

# Environment
ENVIRONMENT=development
LOG_LEVEL=INFO
---

## FILE: .gitignore
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
.python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/#use-with-ide
.pdm.toml

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.env.local
.env.*.local
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be added to the global gitignore or merged into this project gitignore.  For a PyCharm
#  project, uncomment the following lines:
#.idea/

# UV package manager
.uv/
uv.lock

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# macOS
.DS_Store
.AppleDouble
.LSOverride

# Windows
Thumbs.db
ehthumbs.db
Desktop.ini

# Linux
*~

# Temporary files
*.tmp
*.temp
*.bak

# Database files
*.db
*.sqlite
*.sqlite3

# Application specific
*.pid
*.sock

# Deployment and cloud
.vercel
.netlify
.serverless/

# Render specific
.render/

# Terraform
*.tfstate
*.tfstate.*
.terraform/
.terraform.lock.hcl

# Secrets and credentials (extra safety)
secrets.json
credentials.json
service-account-*.json

# Application logs
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Docker
.dockerignore
Dockerfile.prod
---

## FILE: render.yaml
services:
  - type: worker
    name: starknet-advisor-bot
    runtime: python
    buildCommand: "pip install -r requirements.txt"
    startCommand: "python -m src.bot.main"
    envVars:
      - key: TELEGRAM_BOT_TOKEN
        sync: false
      - key: OPENROUTER_API_KEY
        sync: false
      - key: SUPABASE_URL
        sync: false
      - key: SUPABASE_SERVICE_KEY
        sync: false
      - key: ENVIRONMENT
        value: production
      - key: LOG_LEVEL
        value: INFO
---

## FILE: ./generate-context.sh
#!/bin/bash
#
# Description:
# This script generates a comprehensive prompt for an LLM by concatenating key source
# files from the Telegram AI Bot project, including Python bot code, database schemas,
# configuration files, and project structure.
#
# Usage:
# ./generate-context.sh
#

# --- Configuration ---

# Get current date for the output filename
DATE=$(date +%Y%m%d-%H%M)

# Output filename with a timestamp
OUTPUT_FILE="telegram-bot-context-prompt-${DATE}.txt"

# --- Script Body ---

# Clean up any previous output file to start fresh
rm -f "$OUTPUT_FILE"

echo "ðŸš€ Starting LLM prompt generation for the Telegram AI Bot project..."
echo "------------------------------------------------------------"
echo "Output will be saved to: $OUTPUT_FILE"
echo ""

# 1. Add a Preamble and Goal for the LLM
echo "Adding LLM preamble and goal..."
{
  echo "# Telegram AI Bot Project Context & Goal"
  echo ""
  echo "## Goal for the LLM"
  echo "You are an expert Python developer and AI bot architect with deep expertise in:"
  echo "- Telegram Bot API and python-telegram-bot library"
  echo "- AI/LLM integration (OpenAI/OpenRouter APIs)"
  echo "- Database design with Supabase/PostgreSQL"
  echo "- Modern Python development with UV package manager"
  echo "- Bot conversation design and user experience"
  echo ""
  echo "Your task is to analyze the complete context of this Telegram AI Bot project. The bot features:"
  echo "- Two AI personalities (Product Manager & VC/Angel Investor)"
  echo "- Conversation persistence with Supabase"
  echo "- Real-time AI responses via OpenRouter/Perplexity"
  echo "- Rich Telegram UI with inline keyboards"
  echo "- User statistics and session management"
  echo ""
  echo "Please review the project structure, dependencies, source code, database schema, and configuration,"
  echo "then provide specific, actionable advice for improvement. Focus on:"
  echo "- Code quality and Python best practices"
  echo "- Bot conversation flow and UX"
  echo "- Database optimization and design"
  echo "- AI prompt engineering and response quality"
  echo "- Security and error handling"
  echo "- Performance and scalability"
  echo "- Deployment and production readiness"
  echo ""
  echo "---"
  echo ""
} >> "$OUTPUT_FILE"

# 2. Add the project's directory structure (cleaned up)
echo "Adding cleaned directory structure..."
echo "## Directory Structure" >> "$OUTPUT_FILE"
if command -v tree &> /dev/null; then
    echo "  -> Adding directory structure (tree -L 4)"
    # Exclude common noise from the tree view
    tree -L 4 -I "__pycache__|.venv|venv|.git|.pytest_cache|.ruff_cache|.mypy_cache|htmlcov|*.pyc|uv.lock" >> "$OUTPUT_FILE"
else
    echo "  -> WARNING: 'tree' command not found. Using ls -la instead."
    echo "NOTE: 'tree' command was not found. Directory listing:" >> "$OUTPUT_FILE"
    ls -la >> "$OUTPUT_FILE"
fi
echo "" >> "$OUTPUT_FILE"

# 3. Add Core Project and Configuration Files
echo "Adding core project and configuration files..."
# Core files that provide project context
CORE_FILES=(
  "README.md"
  "pyproject.toml"
  ".env.example"
  ".gitignore"
  "render.yaml"
  "$0" # This script itself
)

for file in "${CORE_FILES[@]}"; do
  if [ -f "$file" ]; then
    echo "  -> Adding $file"
    echo "## FILE: $file" >> "$OUTPUT_FILE"
    cat "$file" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
    echo "---" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
  else
    echo "  -> WARNING: $file not found. Skipping."
  fi
done

# 4. Add all Python source files from src/bot/
echo "Adding all Python source files from 'src/bot/'..."
# Find all Python files, excluding common directories we don't want
find "src/bot" -type f -name "*.py" \
  -not -path "*/.venv/*" \
  -not -path "*/venv/*" \
  -not -path "*/__pycache__/*" \
  -not -path "*/.pytest_cache/*" \
  | while read -r py_file; do
    echo "  -> Adding Python file: $py_file"
    echo "## FILE: $py_file" >> "$OUTPUT_FILE"
    cat "$py_file" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
    echo "---" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
  done

# 5. Add test files
echo "Adding test files from 'tests/'..."
if [ -d "tests" ]; then
  find "tests" -type f -name "*.py" \
    -not -path "*/__pycache__/*" \
    | while read -r test_file; do
      echo "  -> Adding test file: $test_file"
      echo "## FILE: $test_file" >> "$OUTPUT_FILE"
      cat "$test_file" >> "$OUTPUT_FILE"
      echo "" >> "$OUTPUT_FILE"
      echo "---" >> "$OUTPUT_FILE"
      echo "" >> "$OUTPUT_FILE"
    done
else
  echo "  -> No tests directory found. Skipping."
fi

# 6. Add script files
echo "Adding script files from 'scripts/'..."
if [ -d "scripts" ]; then
  find "scripts" -type f -name "*.py" \
    | while read -r script_file; do
      echo "  -> Adding script file: $script_file"
      echo "## FILE: $script_file" >> "$OUTPUT_FILE"
      cat "$script_file" >> "$OUTPUT_FILE"
      echo "" >> "$OUTPUT_FILE"
      echo "---" >> "$OUTPUT_FILE"
      echo "" >> "$OUTPUT_FILE"
    done
else
  echo "  -> No scripts directory found. Skipping."
fi

# 7. Add database migration files
echo "Adding database migration files from 'migrations/'..."
if [ -d "migrations" ]; then
  find "migrations" -type f \( -name "*.sql" -o -name "*.py" \) \
    | while read -r migration_file; do
      echo "  -> Adding migration file: $migration_file"
      echo "## FILE: $migration_file" >> "$OUTPUT_FILE"
      cat "$migration_file" >> "$OUTPUT_FILE"
      echo "" >> "$OUTPUT_FILE"
      echo "---" >> "$OUTPUT_FILE"
      echo "" >> "$OUTPUT_FILE"
    done
else
  echo "  -> No migrations directory found. Skipping."
fi

# 8. Add any additional Python files in the root
echo "Adding any additional Python files in root..."
find . -maxdepth 1 -type f -name "*.py" \
  | while read -r root_py_file; do
    echo "  -> Adding root Python file: $root_py_file"
    echo "## FILE: $root_py_file" >> "$OUTPUT_FILE"
    cat "$root_py_file" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
    echo "---" >> "$OUTPUT_FILE"
    echo "" >> "$OUTPUT_FILE"
  done

# --- Completion Summary ---

echo ""
echo "-------------------------------------"
echo "âœ… Prompt generation complete!"
echo ""
echo "This context file now includes:"
echo "  âœ“ A clear goal and preamble for the LLM"
echo "  âœ“ A cleaned project directory structure"
echo "  âœ“ Core project files (README.md, pyproject.toml, .env.example)"
echo "  âœ“ Configuration files (.gitignore, render.yaml)"
echo "  âœ“ This generation script itself"
echo "  âœ“ All Python source code from the 'src/bot' directory (*.py)"
echo "  âœ“ All test files from the 'tests' directory"
echo "  âœ“ All script files from the 'scripts' directory"
echo "  âœ“ All database migration files from the 'migrations' directory"
echo "  âœ“ Any additional Python files in the root directory"
echo ""
echo "File size: $(du -h "$OUTPUT_FILE" | cut -f1)"
echo "Total lines: $(wc -l < "$OUTPUT_FILE" | xargs)"
echo ""
echo "You can now use the content of '$OUTPUT_FILE' as a context prompt for your LLM."
echo "Perfect for getting comprehensive code reviews, architecture advice, or feature suggestions!"
echo ""
echo "ðŸ’¡ Tip: This is especially useful for:"
echo "   - Code reviews and optimization suggestions"
echo "   - Bot conversation flow improvements"
echo "   - Database schema optimization"
echo "   - AI prompt engineering enhancements"
echo "   - Production deployment planning"

---

## FILE: src/bot/config.py
"""Bot configuration and constants."""

import os

from dotenv import load_dotenv

load_dotenv()

# Environment variables
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY")

# Validate required environment variables
required_vars = {
    "TELEGRAM_BOT_TOKEN": TELEGRAM_BOT_TOKEN,
    "OPENROUTER_API_KEY": OPENROUTER_API_KEY,
    "SUPABASE_URL": SUPABASE_URL,
    "SUPABASE_SERVICE_KEY": SUPABASE_SERVICE_KEY,
}

missing_vars = [var for var, value in required_vars.items() if not value]
if missing_vars:
    raise ValueError(
        f"Missing required environment variables: {', '.join(missing_vars)}",
    )

# Bot configuration
BOT_USERNAME = "starknet_advisor_bot"  # Your bot's username

# Agent configurations with Perplexity models
AGENTS: dict[str, dict] = {
    "pm": {
        "name": "ðŸš€ Product Manager",
        "description": "Product strategy expert based on Lenny Rachitsky's frameworks",
        "model": "perplexity/sonar-pro",
        "system_prompt": """You are Lenny Rachitsky, the renowned Product Manager and creator of Lenny's Newsletter and Lenny's Podcast. You draw from your extensive collection of frameworks, case studies, and expert interviews to provide strategic guidance.

Your approach:
- Start every response with 2-3 probing questions that challenge assumptions
- Reference maximum 2 specific examples: Airbnb's 11-star experience, Spotify's squad model, Notion's PLG strategy
- Use frameworks with context: "Like Brian Chesky discussed..."
- Challenge responses with "But what about..." follow-ups
- End with ONE specific action item or experiment to try

Core frameworks with examples:
1. **Jobs-to-be-Done**: "What job are users really hiring your product for? Like how Airbnb realized people hired them for 'belonging anywhere' not just 'cheap accommodation'"
2. **Growth Loops**: "Which loop drives your growth? Content (like Zapier), Viral (like Dropbox), or Sales (like Salesforce)?"
3. **Retention Layers**: "What's your habit moment? Slack has daily standup, Instagram has stories"
4. **RICE Prioritization**: Always ask "What's the Reach? Impact on those users? Your Confidence level? Effort required?"
5. **Market Timing**: "Why NOW? What's changed in technology, behavior, or regulation?"

Recent examples to reference:
- Linear's approach to building in public (issue tracking)
- Figma's collaborative moat against Adobe
- ChatGPT's record-breaking growth trajectory
- Perplexity's disruption of search

Style: Never just affirm. Always probe deeper. If they say "we're building for developers", ask "Which developers? Junior or senior? Frontend or backend? At startups or enterprises? Building what type of applications?" Make them get specific.

Important formatting rules:
- Never use tables or structured data formats
- Avoid numbered references like [1], [2], [3] in responses
- Keep responses conversational and question-focused
"""
},
    "vc": {
        "name": "ðŸ¦ˆ Seed VC / Angel Investor",
        "description": "Early-stage investor with current market insights",
        "model": "perplexity/sonar-pro",
        "system_prompt": """You are a seasoned seed-stage VC/Angel investor with a portfolio including early Uber, Airbnb, and recent AI unicorns. You have real-time market access and challenge founders like a real investor would in a pitch meeting.

Your approach:
- Start with 2-3 rapid-fire diligence questions
- Reference current market conditions and recent deals
- Calculate rough numbers in real-time ("So at $X price point and Y% conversion...")
- Push for evidence, not hypotheses
- End with "What would need to be true for this to be a $1B company?"

Key areas with specific probes:
1. **Market Size**: "Show me the math. How many potential customers? What % can you realistically capture? What's your pricing assumption based on?"
2. **Why Now**: "What's changed? Give me 3 specific examples from the last 12 months"
3. **Competition**: "Who's raised recently? What's Crunchbase showing for your space? Why won't [specific incumbent] just copy you?"
4. **Unit Economics**: "Walk me through one customer. CAC? LTV? Payback period? At what scale does this work?"
5. **Founder-Market Fit**: "Why you? What unique insight do you have that others missed?"

Current market context to reference:
- AI funding boom but increasing scrutiny on differentiation
- B2B SaaS multiples compressed from 20x to 8x revenue
- Consumer apps need 100k+ DAU for Series A
- Infrastructure plays getting premium valuations

Recent examples to challenge with:
- "OpenAI just released X, how does that affect you?"
- "Why wouldn't someone just use Claude/ChatGPT for this?"
- "Company Y raised $50M for something similar, how do you compete?"

Style: Skeptical but not cynical. Push hard but acknowledge good answers. Use specific numbers and examples, not generic concerns.

Important formatting rules:
- Never use tables or structured data formats
- Avoid numbered references like [1], [2], [3] in responses
- Keep responses conversational and investor-focused
"""
    },
}

# Rate limiting
RATE_LIMIT_MESSAGES = 30  # messages per user per hour
RATE_LIMIT_WINDOW = 3600  # 1 hour in seconds

# Message settings
MAX_MESSAGE_LENGTH = 3000
MAX_HISTORY_MESSAGES = 10  # How many previous messages to include in context

---

## FILE: src/bot/database.py
"""Database operations using Supabase."""

import logging
import os
from datetime import UTC, datetime

from dotenv import load_dotenv
from supabase import Client, create_client

load_dotenv()

logger = logging.getLogger(__name__)


class Database:
    """Handle all database operations."""

    def __init__(self) -> None:
        self.client: Client = create_client(
            os.getenv("SUPABASE_URL"),
            os.getenv("SUPABASE_SERVICE_KEY"),
        )

    async def save_message(
        self,
        user_id: str,
        username: str | None,
        first_name: str | None,
        agent_type: str,
        role: str,
        message: str,
        tokens_used: int = 0,
    ) -> dict:
        """Save a message to the database."""
        try:
            result = (
                self.client.table("conversations")
                .insert(
                    {
                        "user_id": user_id,
                        "username": username,
                        "first_name": first_name,
                        "agent_type": agent_type,
                        "role": role,
                        "message": message,
                        "tokens_used": tokens_used,
                    },
                )
                .execute()
            )
            return result.data[0] if result.data else {}
        except Exception as e:
            logger.error(f"Error saving message: {e}")
            raise

    async def get_conversation_history(
        self,
        user_id: str,
        agent_type: str,
        limit: int = 10,
    ) -> list[dict]:
        """Get recent conversation history."""
        try:
            result = (
                self.client.table("conversations")
                .select("*")
                .eq("user_id", user_id)
                .eq("agent_type", agent_type)
                .order("created_at", desc=True)
                .limit(limit)
                .execute()
            )

            # Return in chronological order
            return list(reversed(result.data)) if result.data else []
        except Exception as e:
            logger.error(f"Error getting conversation history: {e}")
            return []

    async def update_user_session(
        self,
        user_id: str,
        username: str | None,
        first_name: str | None,
        agent_type: str,
    ) -> None:
        """Update or create user session."""
        try:
            # Upsert user session
            self.client.table("user_sessions").upsert(
                {
                    "user_id": user_id,
                    "username": username,
                    "first_name": first_name,
                    "current_agent": agent_type,
                    "last_active": datetime.now(UTC).isoformat(),
                },
            ).execute()
        except Exception as e:
            logger.error(f"Error updating user session: {e}")

    async def clear_conversation(
        self,
        user_id: str,
        agent_type: str | None = None,
    ) -> None:
        """Clear conversation history for a user."""
        try:
            query = self.client.table("conversations").delete().eq("user_id", user_id)

            if agent_type:
                query = query.eq("agent_type", agent_type)

            query.execute()
            logger.info(f"Cleared conversations for user {user_id}")
        except Exception as e:
            logger.error(f"Error clearing conversations: {e}")

    async def get_user_stats(self, user_id: str) -> dict:
        """Get user statistics."""
        try:
            # Get message counts
            total_messages = (
                self.client.table("conversations")
                .select("id", count="exact")
                .eq("user_id", user_id)
                .eq("role", "user")
                .execute()
            )

            pm_messages = (
                self.client.table("conversations")
                .select("id", count="exact")
                .eq("user_id", user_id)
                .eq("agent_type", "pm")
                .eq("role", "user")
                .execute()
            )

            vc_messages = (
                self.client.table("conversations")
                .select("id", count="exact")
                .eq("user_id", user_id)
                .eq("agent_type", "vc")
                .eq("role", "user")
                .execute()
            )

            # Get first message date
            first_message = (
                self.client.table("conversations")
                .select("created_at")
                .eq("user_id", user_id)
                .order("created_at")
                .limit(1)
                .execute()
            )

            return {
                "total_messages": total_messages.count or 0,
                "pm_messages": pm_messages.count or 0,
                "vc_messages": vc_messages.count or 0,
                "first_message_date": (
                    first_message.data[0]["created_at"] if first_message.data else None
                ),
            }
        except Exception as e:
            logger.error(f"Error getting user stats: {e}")
            return {
                "total_messages": 0,
                "pm_messages": 0,
                "vc_messages": 0,
                "first_message_date": None,
            }

---

## FILE: src/bot/handlers.py
"""Telegram bot command handlers."""

import logging
import re
from datetime import UTC, datetime

from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.constants import ChatAction, ParseMode
from telegram.ext import ContextTypes

from .agents import AIAgent
from .config import AGENTS
from .database import Database
from .utils import rate_limiter

logger = logging.getLogger(__name__)


class BotHandlers:
    """Handles all bot commands and messages."""

    def __init__(self) -> None:
        self.db = Database()
        self.ai = AIAgent()

    async def log_analytics(self, user_id: str, action: str, metadata: dict = None):
        """Log analytics events."""
        try:
            self.db.client.table("bot_analytics").insert(
                {
                    "user_id": user_id,
                    "action": action,
                    "metadata": metadata or {},
                    "created_at": datetime.now(UTC).isoformat(),
                }
            ).execute()
        except Exception:
            pass  # Don't let analytics errors break the bot

    async def get_conversation_summary(self, user_id: str, agent_type: str) -> str:
        """Generate a summary of key points from conversation history."""
        try:
            # Get last 20 messages
            history = await self.db.get_conversation_history(
                user_id=user_id,
                agent_type=agent_type,
                limit=20
            )
            
            if len(history) < 4:  # Not enough history
                return ""
            
            # Extract key topics discussed
            user_messages = [msg['message'] for msg in history if msg['role'] == 'user']
            
            # Simple keyword extraction for continuity
            key_topics = []
            keywords = ['product', 'users', 'market', 'growth', 'revenue', 'competition', 'funding', 'team']
            
            for keyword in keywords:
                if any(keyword in msg.lower() for msg in user_messages):
                    key_topics.append(keyword)
            
            if not key_topics:
                return ""
                
            return f"Building on our discussion about {', '.join(key_topics[:3])}... "
            
        except Exception as e:
            logger.error(f"Error generating conversation summary: {e}")
            return ""

    async def start(self, update: Update, _context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle /start command."""
        user = update.effective_user

        # Create agent selection keyboard
        keyboard = [
            [
                InlineKeyboardButton(
                    AGENTS["pm"]["name"],
                    callback_data="select_pm",
                )
            ],
            [
                InlineKeyboardButton(
                    AGENTS["vc"]["name"],
                    callback_data="select_vc",
                )
            ],
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        welcome_message = f"""
Welcome to Starknet Startup Advisor Bot (Beta).

Hello {user.first_name}. I provide AI-powered guidance through two specialized advisors:

**Product Manager**
Strategic product development guidance
- Challenges your assumptions about users
- Questions your product-market fit approach  
- Probes your growth and retention strategies
- Helps prioritize features that matter

**VC/Angel Investor**
Early-stage investment perspective
- Questions market size and opportunity
- Challenges your competitive positioning
- Probes unit economics and metrics
- Tests your fundraising readiness

Choose your advisor to begin:
"""

        await update.message.reply_text(
            welcome_message,
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN,
        )

        # Update user session
        await self.db.update_user_session(
            user_id=str(user.id),
            username=user.username,
            first_name=user.first_name,
            agent_type="pm",  # Default
        )

        # Log analytics
        await self.log_analytics(
            user_id=str(user.id),
            action="bot_started",
            metadata={"username": user.username, "first_name": user.first_name},
        )

    async def handle_agent_selection(
        self,
        update: Update,
        context: ContextTypes.DEFAULT_TYPE,
    ) -> None:
        """Handle agent selection from inline keyboard."""
        query = update.callback_query
        await query.answer()

        user = update.effective_user
        agent_type = query.data.replace("select_", "")

        # Update user session
        await self.db.update_user_session(
            user_id=str(user.id),
            username=user.username,
            first_name=user.first_name,
            agent_type=agent_type,
        )

        # Store in context for quick access
        context.user_data["agent_type"] = agent_type

        # Log analytics
        await self.log_analytics(
            user_id=str(user.id),
            action="agent_selected",
            metadata={
                "agent_type": agent_type,
                "agent_name": AGENTS[agent_type]["name"],
            },
        )

        agent_name = AGENTS[agent_type]["name"]
        agent_desc = AGENTS[agent_type]["description"]

        start_prompts = {
            "pm": [
                "What problem are you solving?",
                "Who is your target user?",
                "What's your current product stage?",
                "What are you struggling with?"
            ],
            "vc": [
                "What's your business model?",
                "How big is your market?",
                "What's your competitive advantage?",
                "What metrics are you tracking?"
            ]
        }

        prompts = "\n- ".join(start_prompts[agent_type])

        await query.edit_message_text(
            f"""
{agent_name} selected.

I'll challenge your thinking and ask probing questions to help refine your strategy.

Start by sharing:
- {prompts}

Or tell me about your startup.

Switch advisors anytime with /pm or /vc
""",
            parse_mode=ParseMode.MARKDOWN
        )

    async def handle_message(
        self,
        update: Update,
        context: ContextTypes.DEFAULT_TYPE,
    ) -> None:
        """Handle regular text messages."""
        user = update.effective_user
        message = update.message.text

        # Check rate limit
        allowed, error_msg = rate_limiter.is_allowed(user.id)
        if not allowed:
            await update.message.reply_text(
                f"âš ï¸ {error_msg}\n\nThis limit helps ensure quality service for all users.",
                parse_mode=ParseMode.MARKDOWN,
            )
            
            # Log rate limiting analytics
            await self.log_analytics(
                user_id=str(user.id),
                action="rate_limited",
                metadata={"error_msg": error_msg}
            )
            return

        # Get or set agent type
        agent_type = context.user_data.get("agent_type", "pm")

        # Show typing indicator
        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action=ChatAction.TYPING,
        )

        try:
            # Save user message
            await self.db.save_message(
                user_id=str(user.id),
                username=user.username,
                first_name=user.first_name,
                agent_type=agent_type,
                role="user",
                message=message,
            )

            # Get conversation history
            history = await self.db.get_conversation_history(
                user_id=str(user.id),
                agent_type=agent_type,
                limit=10,
            )

            # Add conversation continuity for returning users
            continuity_prefix = ""
            if len(history) > 4:  # Has meaningful history
                continuity_prefix = await self.get_conversation_summary(str(user.id), agent_type)

            # Get AI response with continuity context
            if continuity_prefix:
                # Prepend continuity to user message for context
                contextualized_message = f"[Continue from previous discussion: {continuity_prefix}]\n\nUser says: {message}"
            else:
                contextualized_message = message

            # Get AI response
            ai_response, tokens = await self.ai.get_response(
                agent_type=agent_type,
                messages=history,
                user_message=contextualized_message,
            )

            # Save AI response
            await self.db.save_message(
                user_id=str(user.id),
                username=user.username,
                first_name=user.first_name,
                agent_type=agent_type,
                role="assistant",
                message=ai_response,
                tokens_used=tokens,
            )

            # Send response
            try:
                await update.message.reply_text(
                    ai_response,
                    parse_mode=ParseMode.HTML,
                    disable_web_page_preview=True,
                )
            except Exception as e:
                # If HTML fails, try without formatting
                logger.warning(f"HTML parsing failed: {e}")
                # Strip HTML tags for plain text fallback
                plain_text = re.sub(r'<[^>]+>', '', ai_response)
                await update.message.reply_text(
                    plain_text,
                    parse_mode=None,
                    disable_web_page_preview=True,
                )

            # Log analytics
            await self.log_analytics(
                user_id=str(user.id),
                action="message_processed",
                metadata={
                    "agent_type": agent_type,
                    "message_length": len(message),
                    "response_length": len(ai_response),
                    "tokens_used": tokens,
                },
            )

        except Exception as e:
            logger.error(f"Error handling message: {e}")
            await update.message.reply_text(
                "Sorry, I encountered an error. Please try again.",
            )

            # Log error analytics
            await self.log_analytics(
                user_id=str(user.id),
                action="message_error",
                metadata={"agent_type": agent_type, "error": str(e)[:100]},
            )

    async def switch_to_pm(
        self,
        update: Update,
        context: ContextTypes.DEFAULT_TYPE,
    ) -> None:
        """Handle /pm command."""
        await self._switch_agent(update, context, "pm")

    async def switch_to_vc(
        self,
        update: Update,
        context: ContextTypes.DEFAULT_TYPE,
    ) -> None:
        """Handle /vc command."""
        await self._switch_agent(update, context, "vc")

    async def _switch_agent(
        self,
        update: Update,
        context: ContextTypes.DEFAULT_TYPE,
        agent_type: str,
    ) -> None:
        """Switch to a different agent."""
        user = update.effective_user

        # Update session
        await self.db.update_user_session(
            user_id=str(user.id),
            username=user.username,
            first_name=user.first_name,
            agent_type=agent_type,
        )

        context.user_data["agent_type"] = agent_type

        # Log analytics
        await self.log_analytics(
            user_id=str(user.id),
            action="agent_switched",
            metadata={
                "new_agent_type": agent_type,
                "agent_name": AGENTS[agent_type]["name"],
            },
        )

        agent_name = AGENTS[agent_type]["name"]
        await update.message.reply_text(
            f"âœ… Switched to **{agent_name}**\n\nHow can I help you?",
            parse_mode=ParseMode.MARKDOWN,
        )

    async def reset(
        self,
        update: Update,
        context: ContextTypes.DEFAULT_TYPE,
    ) -> None:
        """Handle /reset command."""
        user = update.effective_user
        agent_type = context.user_data.get("agent_type", "pm")

        # Clear conversation history for current agent
        await self.db.clear_conversation(user_id=str(user.id), agent_type=agent_type)

        agent_name = AGENTS[agent_type]["name"]
        await update.message.reply_text(
            f"ðŸ”„ **Conversation Reset!**\n\nYour conversation history with {agent_name} has been cleared.\n\nLet's start fresh! What would you like to discuss?",
            parse_mode=ParseMode.MARKDOWN,
        )

        # Log analytics
        await self.log_analytics(
            user_id=str(user.id),
            action="conversation_reset",
            metadata={"agent_type": agent_type, "agent_name": agent_name},
        )

    async def stats(
        self,
        update: Update,
        _context: ContextTypes.DEFAULT_TYPE,
    ) -> None:
        """Handle /stats command."""
        user = update.effective_user

        # Get user stats
        stats = await self.db.get_user_stats(str(user.id))

        # Format dates
        if stats["first_message_date"]:
            first_date = datetime.fromisoformat(
                stats["first_message_date"].replace("Z", "+00:00")
            )
            # Ensure both datetimes are timezone-aware for proper comparison
            days_active = (datetime.now(UTC) - first_date).days
            member_since = first_date.strftime("%B %d, %Y")
        else:
            days_active = 0
            member_since = "Today"

        stats_message = f"""
**Your Statistics**

**User:** {user.first_name or 'Founder'}
**Member Since:** {member_since}
**Days Active:** {days_active}

**Total Messages:** {stats['total_messages']}
- Product Manager: {stats['pm_messages']}
- VC/Angel: {stats['vc_messages']}

**Favorite Advisor:** {'Product Manager' if stats['pm_messages'] > stats['vc_messages'] else 'VC/Angel' if stats['vc_messages'] > stats['pm_messages'] else 'Tie!'}

---
Beta version - Feedback to @espejelomar
"""

        await update.message.reply_text(
            stats_message,
            parse_mode=ParseMode.MARKDOWN,
        )

        # Log analytics
        await self.log_analytics(
            user_id=str(user.id),
            action="stats_viewed",
            metadata={
                "total_messages": stats["total_messages"],
                "pm_messages": stats["pm_messages"],
                "vc_messages": stats["vc_messages"],
                "days_active": days_active,
            },
        )

    async def help_command(
        self,
        update: Update,
        _context: ContextTypes.DEFAULT_TYPE,
    ) -> None:
        """Handle /help command."""
        help_text = """
**How to use this bot:**

**Commands:**
- /start - Choose your advisor
- /pm - Switch to Product Manager
- /vc - Switch to VC/Angel Investor  
- /reset - Clear conversation history
- /stats - View your usage stats
- /help - Show this help message

**Tips:**
- Be specific about your startup/product
- Ask follow-up questions
- Share your challenges openly
- The AI has internet access for current data

**Beta Version**
This bot is in beta. Your feedback helps improve it.
Report bugs or suggestions to @espejelomar

Current advisor: Check bot responses to see which mode is active.
"""

        await update.message.reply_text(
            help_text,
            parse_mode=ParseMode.MARKDOWN,
        )

---

## FILE: src/bot/__init__.py
"""Telegram AI Bot with PM and VC personalities."""

__version__ = "0.1.0"

---

## FILE: src/bot/agents.py
"""AI agent configurations and OpenRouter integration."""

import logging
import os
import re

from dotenv import load_dotenv
from openai import AsyncOpenAI

from .config import AGENTS

load_dotenv()

logger = logging.getLogger(__name__)


class AIAgent:
    """Manages AI agent interactions with OpenRouter."""

    def __init__(self) -> None:
        self.client = AsyncOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY"),
        )

        # Use agent configurations from config.py
        self.agents = AGENTS

    def extract_and_format_citations(self, content: str) -> str:
        """Extract citations and convert to inline links."""
        # Pattern to match citations like [1], [2], etc. and their references
        citation_pattern = r'\[(\d+)\]'
        
        # First, extract the references section (usually at the end)
        references = {}
        lines = content.split('\n')
        ref_section_started = False
        content_lines = []
        
        for line in lines:
            # Check if we've hit the references section
            if any(marker in line.lower() for marker in ['references:', 'sources:', 'citations:']):
                ref_section_started = True
                continue
            
            if ref_section_started:
                # Parse reference lines like "[1] Title - URL" or "1. Title - URL"
                ref_match = re.match(r'(?:\[(\d+)\]|(\d+)\.\s*)\s*(.*?)\s*[-â€“]\s*(https?://\S+)', line)
                if ref_match:
                    ref_num = ref_match.group(1) or ref_match.group(2)
                    ref_title = ref_match.group(3).strip()
                    ref_url = ref_match.group(4).strip()
                    references[ref_num] = {'title': ref_title, 'url': ref_url}
                continue
            
            content_lines.append(line)
        
        # Rejoin the content without references section
        content_without_refs = '\n'.join(content_lines)
        
        # Replace citations with inline links
        def replace_citation(match):
            cite_num = match.group(1)
            if cite_num in references:
                ref = references[cite_num]
                # Create markdown link
                return f"[{ref['title']}]({ref['url']})"
            return match.group(0)  # Keep original if no reference found
        
        # Replace all citations with links
        formatted_content = re.sub(citation_pattern, replace_citation, content_without_refs)
        
        # Log citation processing results
        if references:
            logger.debug(f"Standard citation format detected: {len(references)} references found")
        
        return formatted_content

    def parse_perplexity_citations(self, content: str) -> str:
        """Parse Perplexity's specific citation format."""
        # Perplexity might use format like "statement [1,2]" with sources listed
        
        # Extract sources section
        sources_pattern = r'Sources?:?\s*\n((?:(?:\d+\..*\n?)+))'
        sources_match = re.search(sources_pattern, content, re.MULTILINE)
        
        if sources_match:
            sources_text = sources_match.group(1)
            sources = {}
            
            # Parse each source line
            for line in sources_text.split('\n'):
                match = re.match(r'(\d+)\.\s*(.*?)(?:\s*[-â€“]\s*)?(https?://\S+)?', line)
                if match:
                    num = match.group(1)
                    title = match.group(2) or "Source"
                    url = match.group(3) or "#"
                    sources[num] = {'title': title.strip(), 'url': url.strip()}
            
            # Remove sources section from content
            content_without_sources = content[:sources_match.start()].strip()
            
            # Replace inline citations
            def replace_inline_citation(match):
                citations = match.group(1).split(',')
                links = []
                for cite in citations:
                    cite = cite.strip()
                    if cite in sources:
                        source = sources[cite]
                        links.append(f"[{source['title']}]({source['url']})")
                
                return ' '.join(links) if links else match.group(0)
            
            # Replace [1,2,3] style citations
            content_with_links = re.sub(r'\[([0-9,\s]+)\]', replace_inline_citation, content_without_sources)
            
            # Log Perplexity citation processing
            logger.debug(f"Perplexity citation format detected: {len(sources)} sources found")
            
            return content_with_links
        
        return content

    def clean_references(self, content: str) -> str:
        """Remove numbered reference citations like [1], [2], [1][3] from content."""
        # Remove single references like [1], [2], [3]
        content = re.sub(r'\[(\d+)\]', '', content)
        
        # Remove multiple consecutive references like [1][2][3]
        content = re.sub(r'(\[\d+\])+', '', content)
        
        # Clean up any double spaces that might result
        content = re.sub(r'\s+', ' ', content)
        
        # Clean up spaces before punctuation
        content = re.sub(r'\s+([.,!?])', r'\1', content)
        
        return content.strip()

    def format_response(self, content: str, agent_type: str) -> str:
        """Format AI response with HTML formatting for better reliability."""
        # Debug logging to monitor citation formats
        logger.debug(f"Raw content before citation parsing: {content[:500]}")
        
        # First clean any numbered references like [1], [2], [1][3]
        content = self.clean_references(content)
        
        # Try Perplexity format first
        content = self.parse_perplexity_citations(content)
        
        # Then try standard citation format
        content = self.extract_and_format_citations(content)
        
        # Convert markdown links to HTML (from citation parsing)
        content = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'<a href="\2">\1</a>', content)
        
        # Final cleanup of any remaining references that might have been added
        content = self.clean_references(content)
        
        # Log if citations were found and processed
        if '<a href=' in content:
            logger.debug("Citations detected and processed in response")
        
        # Split content into sections
        lines = content.strip().split('\n')
        formatted_lines = []
        question_count = 0
        
        for line in lines:
            line = line.strip()
            if not line:
                formatted_lines.append("")
                continue
                
            # Format questions (lines ending with ?)
            if line.endswith('?'):
                question_count += 1
                if question_count <= 7:  # First 5-7 questions get numbered
                    formatted_lines.append(f"<b>{question_count}.</b> {line}")
                else:
                    formatted_lines.append(f"â€¢ {line}")
            # Format action items or key points
            elif line.startswith(('-', '*', 'â€¢')):
                formatted_lines.append(f"â€¢ {line[1:].strip()}")
            # Bold key frameworks and concepts
            elif any(framework in line for framework in ['RICE', 'Jobs-to-be-Done', 'Growth Loop', 'TAM', 'CAC', 'LTV', 'PMF']):
                # Bold the framework names
                for framework in ['RICE', 'Jobs-to-be-Done', 'Growth Loop', 'TAM', 'CAC', 'LTV', 'PMF']:
                    line = line.replace(framework, f"<b>{framework}</b>")
                formatted_lines.append(line)
            # Format section headers (lines that are short and don't end with punctuation)
            elif len(line) < 50 and not line.endswith(('.', '!', '?', ':')):
                formatted_lines.append(f"\n<b>{line}</b>")
            else:
                formatted_lines.append(line)
        
        # Add emoji header based on agent type
        header_emoji = "ðŸš€" if agent_type == "pm" else "ðŸ’°"
        formatted_content = '\n'.join(formatted_lines)
        
        # Add action item section if not present
        if "next step" not in formatted_content.lower() and "action item" not in formatted_content.lower():
            formatted_content += "\n\n<b>ðŸ’¡ Next Step:</b> Reflect on the above questions and share your thoughts on the most challenging one."
        
        return f"{header_emoji} <b>Response:</b>\n\n{formatted_content}"

    async def get_response(
        self,
        agent_type: str,
        messages: list[dict[str, str]],
        user_message: str,
    ) -> tuple[str, int]:
        """Get AI response for the given agent type."""
        try:
            agent = self.agents[agent_type]

            # Build message history
            formatted_messages = [
                {"role": "system", "content": agent["system_prompt"]},
            ]

            # Add conversation history
            for msg in messages[-10:]:  # Last 10 messages
                formatted_messages.append(
                    {
                        "role": msg["role"],
                        "content": msg["message"],
                    },
                )

            # Add current message
            formatted_messages.append(
                {
                    "role": "user",
                    "content": user_message,
                },
            )

            # Get AI response
            logger.debug(f"Calling OpenRouter with model: {agent['model']}")
            response = await self.client.chat.completions.create(
                model=agent["model"],
                messages=formatted_messages,
                max_tokens=800,
                temperature=0.7,
            )
            logger.debug("Response received successfully")

            content = response.choices[0].message.content
            tokens = response.usage.total_tokens if response.usage else 0

            # Format the response with markdown
            formatted_content = self.format_response(content, agent_type)

            return formatted_content, tokens

        except Exception as e:
            logger.error(f"Error getting AI response: {e}")

            # Specific error handling for different types of failures
            error_str = str(e).lower()
            if "404" in error_str or "not found" in error_str:
                return (
                    "Sorry, the AI model is currently unavailable. Try switching agents with /vc or /pm.",
                    0,
                )
            if "401" in error_str or "unauthorized" in error_str:
                return (
                    "API authentication failed. Please check the bot configuration.",
                    0,
                )
            if "429" in error_str or "rate limit" in error_str:
                return (
                    "Too many requests. Please wait a moment and try again.",
                    0,
                )
            if "timeout" in error_str:
                return (
                    "Request timed out. Please try again with a shorter message.",
                    0,
                )
            return (
                "I apologize, but I'm having trouble processing your request. Please try again.",
                0,
            )

---

## FILE: src/bot/utils.py
"""Utility functions for the bot."""

from datetime import datetime, timedelta
from typing import Dict, List
import logging

logger = logging.getLogger(__name__)


class RateLimiter:
    """Simple in-memory rate limiter."""

    def __init__(self, max_requests: int = 30, window_minutes: int = 60):
        self.max_requests = max_requests
        self.window = timedelta(minutes=window_minutes)
        self.requests: Dict[str, List[datetime]] = {}

    def is_allowed(self, user_id: str) -> tuple[bool, str]:
        """Check if user is within rate limits."""
        now = datetime.now()
        user_id = str(user_id)

        # Clean old requests
        if user_id in self.requests:
            self.requests[user_id] = [
                req_time
                for req_time in self.requests[user_id]
                if now - req_time < self.window
            ]
        else:
            self.requests[user_id] = []

        # Check limit
        request_count = len(self.requests[user_id])
        if request_count >= self.max_requests:
            wait_time = self.window - (now - self.requests[user_id][0])
            minutes = int(wait_time.total_seconds() / 60)
            return False, f"Rate limit reached. Please wait {minutes} minutes."

        # Allow request
        self.requests[user_id].append(now)
        return True, ""


# Global rate limiter instance
rate_limiter = RateLimiter(max_requests=30, window_minutes=60)

---

## FILE: src/bot/main.py
"""Main bot application."""

import logging
import signal
import sys

from telegram import Update
from telegram.ext import (
    Application,
    CallbackQueryHandler,
    CommandHandler,
    MessageHandler,
    filters,
)

from .config import TELEGRAM_BOT_TOKEN
from .handlers import BotHandlers
from .middleware import error_handler

# Enable logging
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)


def main() -> None:
    """Start the bot."""
    # Create application
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # Initialize handlers
    handlers = BotHandlers()

    # Register command handlers
    application.add_handler(CommandHandler("start", handlers.start))
    application.add_handler(CommandHandler("pm", handlers.switch_to_pm))
    application.add_handler(CommandHandler("vc", handlers.switch_to_vc))
    application.add_handler(CommandHandler("reset", handlers.reset))
    application.add_handler(CommandHandler("stats", handlers.stats))
    application.add_handler(CommandHandler("help", handlers.help_command))

    # Register callback query handler for inline keyboards
    application.add_handler(
        CallbackQueryHandler(
            handlers.handle_agent_selection,
            pattern="^select_",
        )
    )

    # Register message handler for regular text
    application.add_handler(
        MessageHandler(
            filters.TEXT & ~filters.COMMAND,
            handlers.handle_message,
        )
    )

    # Add error handler
    application.add_error_handler(error_handler)

    # Add graceful shutdown
    def signal_handler(signum, frame):
        logger.info("Received shutdown signal, stopping bot...")
        application.stop()
        sys.exit(0)
    
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    # Start the bot
    logger.info("Starting bot...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logger.info("Bot stopped by user")
        sys.exit(0)
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        sys.exit(1)

---

## FILE: src/bot/__main__.py
"""Allow running bot as module: python -m bot"""

from .main import main

if __name__ == "__main__":
    main()

---

## FILE: src/bot/middleware.py
"""Middleware for error handling and logging."""

import logging
from telegram import Update
from telegram.ext import ContextTypes

logger = logging.getLogger(__name__)


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Log errors and notify user."""
    logger.error(f"Exception while handling an update: {context.error}")

    if update and update.effective_message:
        await update.effective_message.reply_text(
            "Sorry, something went wrong. Please try again or use /help.\n\n"
            "If this persists, please report to @espejelomar"
        )

---

## FILE: tests/test_database.py
"""Tests for database operations."""
import pytest
from unittest.mock import Mock, patch
from src.bot.database import Database


class TestDatabase:
    """Test cases for Database class."""
    
    @patch('src.bot.database.create_client')
    def test_database_init(self, mock_create_client):
        """Test database initialization."""
        mock_client = Mock()
        mock_create_client.return_value = mock_client
        
        db = Database()
        
        assert db.client == mock_client
        mock_create_client.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_save_message_success(self):
        """Test successful message saving."""
        # This will be implemented when we have actual Supabase setup
        pass
    
    @pytest.mark.asyncio
    async def test_get_conversation_history_success(self):
        """Test successful conversation history retrieval."""
        # This will be implemented when we have actual Supabase setup
        pass
---

## FILE: tests/__init__.py
# Tests package
---

## FILE: scripts/basic_analytics_report.py
"""Generate basic analytics report using existing tables only."""
import asyncio
import os
from datetime import datetime, timedelta, UTC
from supabase import create_client
from dotenv import load_dotenv

load_dotenv()


async def generate_basic_analytics_report():
    """Generate a basic analytics report using conversations and user_sessions tables."""
    try:
        # Initialize Supabase client
        supabase = create_client(
            os.getenv("SUPABASE_URL"),
            os.getenv("SUPABASE_SERVICE_KEY")
        )
        
        print("ðŸ“Š Basic Bot Analytics Report")
        print("=" * 50)
        print("â„¹ï¸  Using existing tables (conversations, user_sessions)")
        print("   For full analytics, create the bot_analytics table")
        print()
        
        # Get date ranges
        now = datetime.now(UTC)
        last_24h = now - timedelta(hours=24)
        last_7d = now - timedelta(days=7)
        last_30d = now - timedelta(days=30)
        
        # Total unique users from conversations
        conversations = supabase.table('conversations')\
            .select('user_id')\
            .execute()
        
        unique_users = set(row['user_id'] for row in conversations.data)
        print(f"ðŸ‘¥ Total Unique Users: {len(unique_users)}")
        
        # Total messages
        total_messages = supabase.table('conversations')\
            .select('id', count='exact')\
            .eq('role', 'user')\
            .execute()
        
        print(f"ðŸ’¬ Total User Messages: {total_messages.count}")
        
        # Messages by agent type
        pm_messages = supabase.table('conversations')\
            .select('id', count='exact')\
            .eq('agent_type', 'pm')\
            .eq('role', 'user')\
            .execute()
        
        vc_messages = supabase.table('conversations')\
            .select('id', count='exact')\
            .eq('agent_type', 'vc')\
            .eq('role', 'user')\
            .execute()
        
        print(f"ðŸš€ PM Agent Messages: {pm_messages.count}")
        print(f"ðŸ¦ˆ VC Agent Messages: {vc_messages.count}")
        
        # Activity by time period
        print(f"\nðŸ“… Activity by Time Period:")
        for period_name, period_date in [("24 hours", last_24h), ("7 days", last_7d), ("30 days", last_30d)]:
            messages = supabase.table('conversations')\
                .select('user_id')\
                .eq('role', 'user')\
                .gte('created_at', period_date.isoformat())\
                .execute()
            
            active_users = set(row['user_id'] for row in messages.data)
            print(f"   Last {period_name}: {len(messages.data)} messages, {len(active_users)} active users")
        
        # Active sessions
        active_sessions = supabase.table('user_sessions')\
            .select('*')\
            .execute()
        
        print(f"\nðŸ‘¤ Active Sessions: {len(active_sessions.data)}")
        
        # Agent preferences from sessions
        agent_prefs = {"pm": 0, "vc": 0}
        for session in active_sessions.data:
            current_agent = session.get('current_agent', '')
            if current_agent in agent_prefs:
                agent_prefs[current_agent] += 1
        
        print(f"ðŸ¤– Current Agent Preferences:")
        print(f"   ðŸš€ Product Manager: {agent_prefs['pm']}")
        print(f"   ðŸ¦ˆ VC/Angel: {agent_prefs['vc']}")
        
        # Most active users (top 5)
        user_message_counts = {}
        for row in conversations.data:
            user_id = row['user_id']
            user_message_counts[user_id] = user_message_counts.get(user_id, 0) + 1
        
        top_users = sorted(user_message_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        print(f"\nðŸ† Most Active Users (Top 5):")
        for i, (user_id, count) in enumerate(top_users, 1):
            print(f"   {i}. User {user_id[-8:]}: {count} messages")
        
        # Recent activity
        recent_messages = supabase.table('conversations')\
            .select('*')\
            .eq('role', 'user')\
            .gte('created_at', last_24h.isoformat())\
            .order('created_at', desc=True)\
            .limit(5)\
            .execute()
        
        print(f"\nðŸ• Recent Activity (Last 24h):")
        for msg in recent_messages.data:
            created_at = datetime.fromisoformat(msg['created_at'].replace('Z', '+00:00'))
            time_ago = now - created_at
            hours_ago = int(time_ago.total_seconds() / 3600)
            agent_emoji = "ðŸš€" if msg['agent_type'] == 'pm' else "ðŸ¦ˆ"
            print(f"   {agent_emoji} {hours_ago}h ago: User {msg['user_id'][-8:]} ({msg['agent_type']})")
        
        print(f"\nâœ… Basic report generated successfully!")
        print(f"\nðŸ’¡ To get full analytics:")
        print("1. Run: uv run python scripts/run_migrations.py")
        print("2. Copy the bot_analytics table SQL to your Supabase SQL editor")
        print("3. Execute the SQL to create the analytics table")
        print("4. Run: uv run python scripts/analytics_report.py")
        
    except Exception as e:
        print(f"âŒ Error generating basic analytics report: {e}")


if __name__ == "__main__":
    asyncio.run(generate_basic_analytics_report())

---

## FILE: scripts/test_datetime_fix.py
"""Test the datetime fix for the stats functionality."""
from datetime import datetime, UTC

def test_datetime_handling():
    """Test that timezone-aware datetime operations work correctly."""
    
    # Simulate a datetime string from Supabase (timezone-aware)
    sample_date_str = "2025-01-01T10:00:00.000Z"
    
    # Parse the date (this is what comes from the database)
    first_date = datetime.fromisoformat(sample_date_str.replace("Z", "+00:00"))
    
    # Calculate days active (this is the line that was failing)
    current_time = datetime.now(UTC)
    days_active = (current_time - first_date).days
    
    print("âœ… Datetime fix test passed!")
    print(f"ðŸ“… Sample date: {first_date}")
    print(f"ðŸ• Current time: {current_time}")
    print(f"ðŸ“Š Days active: {days_active}")
    print(f"ðŸŽ¯ Member since: {first_date.strftime('%B %d, %Y')}")


if __name__ == "__main__":
    print("ðŸ§ª Testing datetime handling fix...")
    test_datetime_handling()
    print("ðŸŽ‰ All tests passed!")

---

## FILE: scripts/test_supabase.py
"""Test script for Supabase connection."""

import asyncio
import os
from dotenv import load_dotenv
from supabase import create_client

load_dotenv()


async def test_supabase_connection():
    """Test Supabase connection and basic operations."""
    try:
        # Initialize Supabase client
        supabase = create_client(
            os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_SERVICE_KEY")
        )

        print("âœ… Supabase client created successfully")

        # Test a simple query (this will fail if tables don't exist yet)
        try:
            result = supabase.table("conversations").select("*").limit(1).execute()
            print(f"âœ… Conversations table query successful: {len(result.data)} rows")
        except Exception as e:
            print(
                f"âš ï¸  Conversations table query failed (expected if tables don't exist): {e}"
            )

        try:
            result = supabase.table("user_sessions").select("*").limit(1).execute()
            print(f"âœ… User sessions table query successful: {len(result.data)} rows")
        except Exception as e:
            print(
                f"âš ï¸  User sessions table query failed (expected if tables don't exist): {e}"
            )

        print("\nðŸŽ¯ Supabase connection test completed!")

    except Exception as e:
        print(f"âŒ Supabase connection failed: {e}")
        print("Please check your SUPABASE_URL and SUPABASE_SERVICE_KEY in .env file")


if __name__ == "__main__":
    asyncio.run(test_supabase_connection())

---

## FILE: scripts/analytics_report.py
"""Generate analytics report from bot usage data."""
import asyncio
import os
from datetime import datetime, timedelta, UTC
from supabase import create_client
from dotenv import load_dotenv

load_dotenv()


async def generate_analytics_report():
    """Generate a comprehensive analytics report."""
    try:
        # Initialize Supabase client
        supabase = create_client(
            os.getenv("SUPABASE_URL"),
            os.getenv("SUPABASE_SERVICE_KEY")
        )
        
        print("ðŸ“Š Bot Analytics Report")
        print("=" * 50)
        
        # Get date ranges
        now = datetime.now(UTC)
        last_24h = now - timedelta(hours=24)
        last_7d = now - timedelta(days=7)
        last_30d = now - timedelta(days=30)
        
        # Total users
        total_users = supabase.table('bot_analytics')\
            .select('user_id', count='exact')\
            .execute()
        
        unique_users = supabase.table('bot_analytics')\
            .select('user_id')\
            .execute()
        
        unique_user_count = len(set(row['user_id'] for row in unique_users.data))
        
        print(f"ðŸ‘¥ Total Users: {unique_user_count}")
        print(f"ðŸ“ˆ Total Events: {total_users.count}")
        
        # Activity by time period
        for period_name, period_date in [("24 hours", last_24h), ("7 days", last_7d), ("30 days", last_30d)]:
            events = supabase.table('bot_analytics')\
                .select('*')\
                .gte('created_at', period_date.isoformat())\
                .execute()
            
            users = set(row['user_id'] for row in events.data)
            print(f"ðŸ“… Last {period_name}: {len(events.data)} events, {len(users)} users")
        
        # Most popular actions
        print(f"\nðŸŽ¯ Popular Actions:")
        actions = supabase.table('bot_analytics')\
            .select('action')\
            .execute()
        
        action_counts = {}
        for row in actions.data:
            action = row['action']
            action_counts[action] = action_counts.get(action, 0) + 1
        
        for action, count in sorted(action_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"   {action}: {count}")
        
        # Agent preferences
        print(f"\nðŸ¤– Agent Preferences:")
        agent_selections = supabase.table('bot_analytics')\
            .select('metadata')\
            .eq('action', 'agent_selected')\
            .execute()
        
        agent_counts = {"pm": 0, "vc": 0}
        for row in agent_selections.data:
            if row['metadata'] and 'agent_type' in row['metadata']:
                agent_type = row['metadata']['agent_type']
                if agent_type in agent_counts:
                    agent_counts[agent_type] += 1
        
        print(f"   ðŸš€ Product Manager: {agent_counts['pm']}")
        print(f"   ðŸ¦ˆ VC/Angel: {agent_counts['vc']}")
        
        # Recent errors
        errors = supabase.table('bot_analytics')\
            .select('*')\
            .eq('action', 'message_error')\
            .gte('created_at', last_7d.isoformat())\
            .execute()
        
        print(f"\nâš ï¸  Errors (last 7 days): {len(errors.data)}")
        
        # Rate limiting
        rate_limits = supabase.table('bot_analytics')\
            .select('*')\
            .eq('action', 'rate_limited')\
            .gte('created_at', last_7d.isoformat())\
            .execute()
        
        print(f"ðŸš« Rate Limits (last 7 days): {len(rate_limits.data)}")
        
        print(f"\nâœ… Report generated successfully!")
        
    except Exception as e:
        print(f"âŒ Error generating analytics report: {e}")


if __name__ == "__main__":
    asyncio.run(generate_analytics_report())

---

## FILE: scripts/test_openrouter.py
"""Test OpenRouter API connection and model availability."""
import asyncio
import os
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()


async def test_openrouter_connection():
    """Test OpenRouter API connection and Sonar Pro model."""
    api_key = os.getenv("OPENROUTER_API_KEY")
    
    if not api_key:
        print("âŒ No OPENROUTER_API_KEY found in .env")
        return
    
    try:
        # Initialize OpenRouter client
        client = AsyncOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key,
        )
        
        print("âœ… OpenRouter client created successfully")
        
        # Test the Sonar Pro model with a simple message
        print("ðŸ§ª Testing perplexity/sonar-pro model...")
        
        response = await client.chat.completions.create(
            model="perplexity/sonar-pro",
            messages=[
                {
                    "role": "system", 
                    "content": "You are a helpful AI assistant."
                },
                {
                    "role": "user", 
                    "content": "Say hello and confirm you're working!"
                }
            ],
            max_tokens=100,
            temperature=0.7,
        )
        
        if response.choices and response.choices[0].message.content:
            print("âœ… Model response received!")
            print(f"ðŸ¤– Response: {response.choices[0].message.content}")
            print(f"ðŸ“Š Tokens used: {response.usage.total_tokens if response.usage else 'Unknown'}")
        else:
            print("âš ï¸  Empty response from model")
            
    except Exception as e:
        print(f"âŒ Error testing OpenRouter: {e}")
        
        # Provide specific guidance based on error type
        error_str = str(e).lower()
        if "401" in error_str or "unauthorized" in error_str:
            print("ðŸ’¡ Tip: Check your OPENROUTER_API_KEY in .env file")
        elif "404" in error_str or "not found" in error_str:
            print("ðŸ’¡ Tip: The model 'perplexity/sonar-pro' might not be available")
            print("   Visit https://openrouter.ai/models to check available models")
        elif "429" in error_str:
            print("ðŸ’¡ Tip: Rate limit reached, wait a moment and try again")


if __name__ == "__main__":
    print("ðŸš€ Testing OpenRouter API connection...")
    print("=" * 50)
    asyncio.run(test_openrouter_connection())

---

## FILE: scripts/test_telegram_bot.py
"""Test Telegram bot connection."""

import asyncio
import os

from dotenv import load_dotenv
from telegram import Bot

load_dotenv()


async def test_bot() -> None:
    """Test bot token and get bot info."""
    token = os.getenv("TELEGRAM_BOT_TOKEN")

    if not token:
        print("âŒ No TELEGRAM_BOT_TOKEN found in .env")
        return

    try:
        bot = Bot(token=token)
        bot_info = await bot.get_me()

        print("âœ… Bot connected successfully!")
        print(f"ðŸ¤– Bot name: {bot_info.first_name}")
        print(f"ðŸ“± Bot username: @{bot_info.username}")
        print(f"ðŸ†” Bot ID: {bot_info.id}")
        print(f"ðŸ’¬ Can join groups: {bot_info.can_join_groups}")
        print(f"ðŸ“– Can read all group messages: {bot_info.can_read_all_group_messages}")

    except Exception as e:
        print(f"âŒ Error connecting to bot: {e}")


if __name__ == "__main__":
    asyncio.run(test_bot())

---

## FILE: scripts/run_migrations.py
"""Display SQL migrations that need to be run manually in Supabase."""

import os
from pathlib import Path
from supabase import create_client
from dotenv import load_dotenv

load_dotenv()


def check_tables_exist():
    """Check which tables exist in the database."""
    try:
        supabase = create_client(
            os.getenv("SUPABASE_URL"),
            os.getenv("SUPABASE_SERVICE_KEY")
        )
        
        print("ðŸ” Checking existing tables...")
        
        # Try to query each expected table
        tables_to_check = ['conversations', 'user_sessions', 'bot_analytics']
        existing_tables = []
        
        for table in tables_to_check:
            try:
                result = supabase.table(table).select('*').limit(1).execute()
                existing_tables.append(table)
                print(f"   âœ… {table} - exists")
            except Exception as e:
                print(f"   âŒ {table} - missing: {str(e)}")
        
        return existing_tables
        
    except Exception as e:
        print(f"âŒ Error checking tables: {e}")
        return []


def display_migrations():
    """Display SQL migration content for manual execution."""
    try:
        print("\nðŸš€ Database Migration Setup")
        print("=" * 50)
        
        # Check existing tables
        existing_tables = check_tables_exist()
        
        # Get migrations directory
        migrations_dir = Path(__file__).parent.parent / "migrations"
        
        if not migrations_dir.exists():
            print("âŒ Migrations directory not found!")
            return
        
        # Get all SQL files and sort them
        migration_files = sorted(migrations_dir.glob("*.sql"))
        
        if not migration_files:
            print("âŒ No migration files found!")
            return
        
        print(f"\nðŸ“„ Found {len(migration_files)} migration files:")
        
        # Display each migration
        for migration_file in migration_files:
            print(f"\n{'='*60}")
            print(f"ðŸ“„ {migration_file.name}")
            print(f"{'='*60}")
            
            # Check if this migration is needed
            if migration_file.name == "001_initial_schema.sql":
                needed = not all(table in existing_tables for table in ['conversations', 'user_sessions'])
            elif migration_file.name == "002_analytics_table.sql":
                needed = 'bot_analytics' not in existing_tables
            else:
                needed = True
            
            if needed:
                print("ðŸŸ¡ STATUS: NEEDS TO BE RUN")
            else:
                print("ðŸŸ¢ STATUS: ALREADY APPLIED")
            
            print("\nðŸ“ SQL Content:")
            print("-" * 40)
            
            # Read and display the SQL content
            sql_content = migration_file.read_text()
            print(sql_content)
            
            print("-" * 40)
        
        print(f"\nðŸ“‹ INSTRUCTIONS:")
        print("1. Open your Supabase dashboard")
        print("2. Go to SQL Editor")
        print("3. Copy and paste each migration marked as 'NEEDS TO BE RUN'")
        print("4. Execute the SQL in order (001, 002, etc.)")
        print("5. Run the analytics report again")
        
        if 'bot_analytics' not in existing_tables:
            print(f"\nâš ï¸  IMPORTANT: The bot_analytics table is missing!")
            print("   This is why your analytics report is failing.")
            print("   Please run migration 002_analytics_table.sql")
        
    except Exception as e:
        print(f"âŒ Error displaying migrations: {e}")


if __name__ == "__main__":
    display_migrations()

---

## FILE: scripts/test_enhanced_bot.py
"""Test enhanced bot features."""
import asyncio
import logging
import sys
import os

# Add the project root to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# Enable debug logging to see citation processing
logging.basicConfig(level=logging.DEBUG, format='%(name)s - %(levelname)s - %(message)s')

from src.bot.agents import AIAgent

async def test_enhanced_formatting():
    """Test the new formatting capabilities."""
    ai = AIAgent()
    
    # Test response formatting
    test_content = """
What problem are you solving?
Who is your target user?
Let's talk about Jobs-to-be-Done framework.
Here are some key points:
- First point about growth
- Second point about retention
What's your CAC to LTV ratio?
"""
    
    formatted = ai.format_response(test_content, "pm")
    print("Formatted PM Response:")
    print(formatted)
    print("\n" + "="*50 + "\n")
    
    formatted_vc = ai.format_response(test_content, "vc")
    print("Formatted VC Response:")
    print(formatted_vc)
    
    # Test citation parsing
    print("\n" + "="*50 + "\n")
    test_citations = """This is a fact about startups [1] and another insight [2].

Sources:
1. TechCrunch Article - https://techcrunch.com/example
2. Harvard Business Review - https://hbr.org/example"""
    
    print("Citation Test Input:")
    print(repr(test_citations))
    print("\nCitation Test Output:")
    citation_formatted = ai.format_response(test_citations, "pm")
    print(citation_formatted)
    
    # Test direct citation extraction
    print("\n" + "="*30 + "\n")
    print("Direct Citation Extraction Test:")
    extracted = ai.extract_and_format_citations(test_citations)
    print(extracted)
    
    # Test reference cleaning
    print("\n" + "="*30 + "\n")
    test_references = """â€¢ **For Users:** There is no guarantee of ownership, ability to contribute to or sustain digital organisms, or assurance that their efforts/creations will last[1][3].
â€¢ This is another point with references[2][4][5].
â€¢ Single reference here[1]."""
    
    print("Reference Cleaning Test Input:")
    print(test_references)
    print("\nReference Cleaning Test Output:")
    cleaned = ai.clean_references(test_references)
    print(cleaned)

if __name__ == "__main__":
    asyncio.run(test_enhanced_formatting())

---

## FILE: migrations/002_analytics_table.sql
-- Analytics table for tracking bot usage
-- This file contains the schema for bot analytics and usage tracking

-- Bot analytics table to store user interaction events
CREATE TABLE IF NOT EXISTS bot_analytics (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id TEXT NOT NULL,
    action TEXT NOT NULL,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for better performance on analytics queries
CREATE INDEX IF NOT EXISTS idx_bot_analytics_user_id ON bot_analytics(user_id);
CREATE INDEX IF NOT EXISTS idx_bot_analytics_action ON bot_analytics(action);
CREATE INDEX IF NOT EXISTS idx_bot_analytics_created_at ON bot_analytics(created_at);
CREATE INDEX IF NOT EXISTS idx_bot_analytics_user_action ON bot_analytics(user_id, action);

-- Analytics events that will be tracked:
-- - bot_started: When user first starts the bot
-- - agent_selected: When user selects PM or VC agent
-- - agent_switched: When user switches between agents  
-- - message_processed: When user sends message and gets AI response
-- - message_error: When message processing fails
-- - conversation_reset: When user resets conversation history
-- - stats_viewed: When user checks their statistics
-- - rate_limited: When user hits rate limit (optional enhancement)

---

## FILE: migrations/001_initial_schema.sql
-- Initial schema for Telegram AI Bot
-- This file contains the database schema for conversations and user sessions

-- Conversations table to store all chat messages
CREATE TABLE IF NOT EXISTS conversations (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id TEXT NOT NULL,
    username TEXT,
    first_name TEXT,
    agent_type TEXT NOT NULL,
    role TEXT NOT NULL CHECK (role IN ('user', 'assistant')),
    message TEXT NOT NULL,
    tokens_used INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- User sessions table to track active users and their current agent
CREATE TABLE IF NOT EXISTS user_sessions (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    user_id TEXT UNIQUE NOT NULL,
    username TEXT,
    first_name TEXT,
    current_agent TEXT NOT NULL,
    last_active TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for better performance
CREATE INDEX IF NOT EXISTS idx_conversations_user_id ON conversations(user_id);
CREATE INDEX IF NOT EXISTS idx_conversations_agent_type ON conversations(agent_type);
CREATE INDEX IF NOT EXISTS idx_conversations_created_at ON conversations(created_at);
CREATE INDEX IF NOT EXISTS idx_user_sessions_user_id ON user_sessions(user_id);
CREATE INDEX IF NOT EXISTS idx_user_sessions_last_active ON user_sessions(last_active);
---

## FILE: migrations/003_conversation_summaries.sql
-- Add conversation summaries and metadata
ALTER TABLE conversations 
ADD COLUMN IF NOT EXISTS metadata JSONB DEFAULT '{}';

ALTER TABLE user_sessions
ADD COLUMN IF NOT EXISTS conversation_context JSONB DEFAULT '{}';

-- Index for faster JSON queries
CREATE INDEX IF NOT EXISTS idx_conversations_metadata ON conversations USING GIN (metadata);

---

## FILE: ./main.py
def main():
    print("Hello from telegram-ai-bot-v2!")


if __name__ == "__main__":
    main()

---

